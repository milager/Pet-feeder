{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pet feeder - Live Demo\n",
    "\n",
    "The Jetson will in this demo see if the bowl is empty or full. If empty it will loose the grip (on a feeding bag), and when the bowl is full it will tighten the grip again  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch2trt import TRTModule\n",
    "\n",
    "device = torch.device('cuda')\n",
    "model_trt = TRTModule()\n",
    "model_trt.load_state_dict(torch.load('model_trt.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a preprocessing function\n",
    "\n",
    "To match the format of the trained model to the camera, a preprocessing function is necessary. This will convert HWC layout to CHW layout, normalize, transfer data from CPU to GPU memory and add a batch dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "\n",
    "mean = torch.Tensor([0.485, 0.456, 0.406]).cuda().half()\n",
    "std = torch.Tensor([0.229, 0.224, 0.225]).cuda().half()\n",
    "\n",
    "normalize = torchvision.transforms.Normalize(mean, std)\n",
    "\n",
    "def preprocess(image):\n",
    "    image = PIL.Image.fromarray(image)\n",
    "    image = transforms.functional.to_tensor(image).to(device).half()\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating camera and widgets to show prediction of empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traitlets\n",
    "from IPython.display import display\n",
    "import ipywidgets.widgets as widgets\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "\n",
    "camera = Camera.instance(width=224, height=224)\n",
    "image = widgets.Image(format='jpeg', width=224, height=224)\n",
    "empty_slider = widgets.FloatSlider(description='empty', min=0.0, max=1.0, orientation='vertical')\n",
    "full_slider = widgets.FloatSlider(description='full', min=0.0, max=1.0, orientation='vertical')\n",
    "\n",
    "camera_link = traitlets.dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to grab or loose the grip, depending on the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeeded to open the port\n",
      "Succeeded to change the baudrate\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import time\n",
    "from jetbot import Robot\n",
    "from SCSCtrl import TTLServo\n",
    "\n",
    "# Creating robot to enable grabber\n",
    "robot = Robot()\n",
    "\n",
    "def grab():\n",
    "    TTLServo.servoAngleCtrl(4, -90, 1, 150)\n",
    "    \n",
    "def loose():\n",
    "    TTLServo.servoAngleCtrl(4, -10, 1, 150)\n",
    "\n",
    "def update(change):\n",
    "    global empty_slider, full_slider, robot\n",
    "    new_image = change['new'] \n",
    "    new_image = preprocess(new_image)\n",
    "    trt_image = model_trt(new_image)\n",
    "    \n",
    "    # normalizing the output vector by using softmax\n",
    "    trt_image = F.softmax(trt_image, dim=1)\n",
    "    \n",
    "    prob_empty = float(trt_image.flatten()[0])\n",
    "    prob_full = float(trt_image.flatten()[1])\n",
    "    \n",
    "    empty_slider.value = prob_empty\n",
    "    full_slider.value = prob_full\n",
    "    \n",
    "    # If the probability of an empty bowl is more than 80% then loose the grip\n",
    "    if prob_empty > 0.8:\n",
    "        loose()\n",
    "    else:\n",
    "        grab()\n",
    "        \n",
    "update({'new': camera.value})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attaching the execution to the camera using observe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c205d2f4f895408bbef473746b917b89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\xâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "camera.observe(update, names='value')\n",
    "\n",
    "# Displaying image and sliders\n",
    "display(widgets.VBox([widgets.HBox([image, empty_slider, full_slider])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To stop the robot and turn off the camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "camera.unobserve(update, names='value')\n",
    "\n",
    "time.sleep(0.1)  # add a small sleep to make sure frames have finished processing\n",
    "\n",
    "robot.stop()\n",
    "\n",
    "camera.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
